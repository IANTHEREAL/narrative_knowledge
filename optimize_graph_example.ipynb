{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Initialize logging module with a basic configuration for console output\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s] %(levelname)s - %(filename)s:%(lineno)d: %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from graph_optimization_engine import OptimizationConfig, ProcessingConfig, LLMConfig, GraphOptimizationEngine\n",
    "\n",
    "llm_config = LLMConfig(\n",
    "    optimization_provider=\"openai_like\",\n",
    "    optimization_model=\"graph_optimization_14b\",\n",
    "    critique_provider=\"gemini\",\n",
    "    critique_model=\"gemini-2.5-pro\",\n",
    ")\n",
    "\n",
    "processing_config = ProcessingConfig(\n",
    "    max_concurrent_issues=3,\n",
    "    state_file_path=\"optimization_state.pkl\",\n",
    ")\n",
    "\n",
    "config = OptimizationConfig(\n",
    "    database_uri=os.getenv(\"GRAPH_DATABASE_URI\"),\n",
    "    llm_config=llm_config,\n",
    "    processing_config=processing_config,\n",
    ")\n",
    "\n",
    "engine = GraphOptimizationEngine(config)\n",
    "\n",
    "res = engine.optimize_graph(query=\"Which metrics does customer care about?\", top_k=30)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import text\n",
    "\n",
    "from llm.factory import LLMInterface\n",
    "from setting.db import db_manager\n",
    "from utils.json_utils import robust_json_parse\n",
    "from optimization import improve_graph\n",
    "\n",
    "llm_client = LLMInterface(\"openai_like\", \"qwen3-32b\")\n",
    "\n",
    "session_factory = db_manager.get_session_factory(os.getenv(\"GRAPH_DATABASE_URI\"))\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        with session_factory() as session:\n",
    "            sql = text(\n",
    "                f\"\"\"SELECT id, name, description, attributes from entities where updated_at <= '2025-06-21 14:28:44' order by updated_at limit 10\"\"\"\n",
    "            )\n",
    "            res = session.execute(sql)\n",
    "            if res.rowcount == 0:\n",
    "                print(\"No entities found, complete one round\")\n",
    "                break\n",
    "            \n",
    "            entities = {}\n",
    "            for row in res.fetchall():\n",
    "                entities[row.id] = {\n",
    "                    \"id\": row.id,\n",
    "                    \"name\": row.name,\n",
    "                    \"description\": row.description,\n",
    "                    \"attributes\": row.attributes,\n",
    "                }\n",
    "    except Exception as e:\n",
    "        print(f\"Error to get entities: {e}\")\n",
    "        continue\n",
    "\n",
    "    prompt = f\"\"\"Please construct 3-5 natural language queries based on provided entities, these queries will used to similar retrieve (vector similarity) related entities from the graph.\n",
    "\n",
    "Entities:\n",
    "{entities}\n",
    "\n",
    "response in json array format (surround with ```json and ```):\n",
    "```json\n",
    "[query1, query2, query3]\n",
    "```\n",
    "\n",
    "Now please construct the natural language queries:\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = llm_client.generate(prompt)\n",
    "        queries = robust_json_parse(response, llm_client, expected_format=\"array\")\n",
    "        print(queries)\n",
    "    except Exception as e:\n",
    "        print(f\"Error to generate queries: {e}\")\n",
    "        continue\n",
    "\n",
    "    for query in queries:\n",
    "        print(f\"Improve graph with query: {query}\")\n",
    "        try:\n",
    "            engine.optimize_graph(query=query, top_k=30)\n",
    "        except Exception as e:\n",
    "            print(f\"Error to improve graph: {e}\")\n",
    "            continue\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
