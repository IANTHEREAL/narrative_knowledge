{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from llm.factory import LLMInterface\n",
    "from llm.embedding import get_text_embedding\n",
    "from setting.db import db_manager\n",
    "from knowledge_graph.knowledge import KnowledgeBuilder\n",
    "from knowledge_graph.graph_builder import KnowledgeGraphBuilder\n",
    "\n",
    "llm_client = LLMInterface(\"ollama\", \"qwen3:32b-fp16\")\n",
    "session_factory = db_manager.get_session_factory(os.getenv(\"GRAPH_DATABASE_URI\"))\n",
    "kb_builder = KnowledgeBuilder(llm_client, get_text_embedding, session_factory)\n",
    "graph_builder = KnowledgeGraphBuilder(llm_client, get_text_embedding, session_factory)\n",
    "\n",
    "# Initialize logging module with a basic configuration for console output\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='[%(asctime)s] %(levelname)s - %(filename)s:%(lineno)d: %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "\n",
    "categories = [\n",
    "    'tidbcloud/API/API Overview',\n",
    "    'tidbcloud/About TiDB Cloud',\n",
    "]\n",
    "\n",
    "# Define the path to the JSON configuration file\n",
    "config_file_path = '/Users/ian/Work/docs/toc_files_for_tidb_cloud.json'\n",
    "\n",
    "# Variable to store the loaded data\n",
    "loaded_docs = []\n",
    "\n",
    "# Read the JSON configuration file\n",
    "try:\n",
    "    with open(config_file_path, 'r', encoding='utf-8') as f:\n",
    "        loaded_docs = json.load(f)\n",
    "    print(f\"Successfully loaded configuration from: {config_file_path}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Configuration file not found at '{config_file_path}'\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Could not decode JSON from file '{config_file_path}'. Check file format.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred while reading the file: {e}\")\n",
    "\n",
    "if len(loaded_docs) > 0:\n",
    "    print(\"\\nExample: Accessing first document data:\")\n",
    "    print(loaded_docs[0])\n",
    "else:\n",
    "    print(\"\\nConfiguration file is empty.\")\n",
    "\n",
    "\n",
    "tidb_product_docs = {}\n",
    "for category in categories:\n",
    "    topic_name = \"TiDBCloud Product Documentation - \" + category\n",
    "    tidb_product_docs[topic_name] = []\n",
    "    topic_docs = set()\n",
    "    for doc in loaded_docs:\n",
    "        if category == doc['category']:\n",
    "            topic_id = f\"{category}-{doc['web_view_link']}\"\n",
    "            if topic_id in topic_docs:\n",
    "                continue\n",
    "            topic_docs.add(topic_id)\n",
    "            tidb_product_docs[topic_name].append({\n",
    "                'topic_name': topic_name,\n",
    "                'path': doc['path'],  # required\n",
    "                'doc_link': doc['web_view_link'], # required\n",
    "                'category': category,\n",
    "                'updated_at': doc['modified_time'],\n",
    "                'mime_type': doc['mime_type'],\n",
    "                'version': \"2025-07-07\"\n",
    "            })\n",
    "    print(f\"Topic: {topic_name}, Number of documents: {len(tidb_product_docs[topic_name])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restful API Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name = \"TiDB Product Documentation - tidb/Get Started\"\n",
    "topic_docs = tidb_product_docs[topic_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload documents by topic. \n",
    "\n",
    "The same document can be uploaded to different topics repeatedly, and the backend will automatically handle deduplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://192.168.206.252:23333/api/v1/knowledge/upload\"\n",
    "\n",
    "files = []\n",
    "links = []\n",
    "for doc in topic_docs:\n",
    "    files.append(('files', (doc[\"path\"].split('/')[-1], open(doc[\"path\"], 'rb'), 'application/pdf')))\n",
    "    links.append(doc[\"doc_link\"])\n",
    "\n",
    "data = {\n",
    "    'links': links,\n",
    "    'topic_name': topic_name,\n",
    "    'database_uri': os.getenv(\"GRAPH_DATABASE_URI\")\n",
    "}\n",
    "response = requests.post(url, files=files, data=data)\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Graph\n",
    "\n",
    "After documents are uploaded to the same topic, a build of the corresponding graph can be triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "database_uri = os.getenv(\"GRAPH_DATABASE_URI\")\n",
    "\n",
    "# Call the trigger-processing API to start processing uploaded all documents for a topic\n",
    "url = \"http://192.168.206.252:23333/api/v1/knowledge/trigger-processing\"\n",
    "data = {\n",
    "    \"topic_name\": topic_name,\n",
    "    \"database_uri\": database_uri\n",
    "}\n",
    "\n",
    "response = requests.post(url, data=data)\n",
    "print(response.status_code)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Similarity based Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knowledge_graph.query import search_relationships_by_vector_similarity, query_topic_graph\n",
    "\n",
    "query = \"Where are li ming now?\"\n",
    "res = search_relationships_by_vector_similarity(query, similarity_threshold=0.2, top_k=20)\n",
    "context = \"\"\n",
    "entities = set()\n",
    "relationships = []\n",
    "\n",
    "for index, row in res.iterrows():\n",
    "    entities.add(f\"{row['source_entity']} {row['source_entity_description']}\")\n",
    "    entities.add(f\"{row['target_entity']} {row['target_entity_description']}\")\n",
    "    relationships.append(f\"{row['source_entity']} {row['relationship_desc']} {row['target_entity']}\")\n",
    "\n",
    "context = \"Entities:\\n\" + \"\\n\".join(entities) + \"\\n\\nRelationships:\\n\" + \"\\n\".join(relationships)\n",
    "\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm.factory import LLMInterface\n",
    "\n",
    "llm_client = LLMInterface(\"bedrock\", \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\")\n",
    "response =llm_client.generate(f\"\"\"Given the following context\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "answer the question: {query}\n",
    "\"\"\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
